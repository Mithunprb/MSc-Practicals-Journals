\documentclass[11pt]{article}

    \usepackage[breakable]{tcolorbox}
    \usepackage{parskip} % Stop auto-indenting (to mimic markdown behaviour)
    

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % Maintain compatibility with old templates. Remove in nbconvert 6.0
    \let\Oldincludegraphics\includegraphics
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionFormat{nocaption}{}
    \captionsetup{format=nocaption,aboveskip=0pt,belowskip=0pt}

    \usepackage{float}
    \floatplacement{figure}{H} % forces figures to be placed at the correct location
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro

    \usepackage{iftex}
    \ifPDFTeX
        \usepackage[T1]{fontenc}
        \IfFileExists{alphabeta.sty}{
              \usepackage{alphabeta}
          }{
              \usepackage[mathletters]{ucs}
              \usepackage[utf8x]{inputenc}
          }
    \else
        \usepackage{fontspec}
        \usepackage{unicode-math}
    \fi

    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range
    \makeatletter % fix for old versions of grffile with XeLaTeX
    \@ifpackagelater{grffile}{2019/11/01}
    {
      % Do nothing on new versions
    }
    {
      \def\Gread@@xetex#1{%
        \IfFileExists{"\Gin@base".bb}%
        {\Gread@eps{\Gin@base.bb}}%
        {\Gread@@xetex@aux#1}%
      }
    }
    \makeatother
    \usepackage[Export]{adjustbox} % Used to constrain images to a maximum size
    \adjustboxset{max size={0.9\linewidth}{0.9\paperheight}}

    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    % The default LaTeX title has an obnoxious amount of whitespace. By default,
    % titling removes some of it. It also provides customization options.
    \usepackage{titling}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage{array}     % table support for pandoc >= 2.11.3
    \usepackage{calc}      % table minipage width calculation for pandoc >= 2.11.1
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{mathrsfs}
    

    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % common color for the border for error outputs.
    \definecolor{outerrorbackground}{HTML}{FFDFDF}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    % \title{509\_Mithun\_Parab\_mldl-assignment}
    
    
    
    
    
% Pygments definitions
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\@namedef{PY@tok@w}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\@namedef{PY@tok@c}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cp}{\def\PY@tc##1{\textcolor[rgb]{0.61,0.40,0.00}{##1}}}
\@namedef{PY@tok@k}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kt}{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\@namedef{PY@tok@o}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ow}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@nb}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nf}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@ne}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.80,0.25,0.22}{##1}}}
\@namedef{PY@tok@nv}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@no}{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\@namedef{PY@tok@nl}{\def\PY@tc##1{\textcolor[rgb]{0.46,0.46,0.00}{##1}}}
\@namedef{PY@tok@ni}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.44,0.44,0.44}{##1}}}
\@namedef{PY@tok@na}{\def\PY@tc##1{\textcolor[rgb]{0.41,0.47,0.13}{##1}}}
\@namedef{PY@tok@nt}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nd}{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@s}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sd}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@si}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.64,0.35,0.47}{##1}}}
\@namedef{PY@tok@se}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.36,0.12}{##1}}}
\@namedef{PY@tok@sr}{\def\PY@tc##1{\textcolor[rgb]{0.64,0.35,0.47}{##1}}}
\@namedef{PY@tok@ss}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sx}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@m}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@gh}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@gu}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\@namedef{PY@tok@gd}{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\@namedef{PY@tok@gi}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.52,0.00}{##1}}}
\@namedef{PY@tok@gr}{\def\PY@tc##1{\textcolor[rgb]{0.89,0.00,0.00}{##1}}}
\@namedef{PY@tok@ge}{\let\PY@it=\textit}
\@namedef{PY@tok@gs}{\let\PY@bf=\textbf}
\@namedef{PY@tok@gp}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@go}{\def\PY@tc##1{\textcolor[rgb]{0.44,0.44,0.44}{##1}}}
\@namedef{PY@tok@gt}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\@namedef{PY@tok@err}{\def\PY@bc##1{{\setlength{\fboxsep}{\string -\fboxrule}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}}
\@namedef{PY@tok@kc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kd}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kr}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@bp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@fm}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@vc}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vg}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vi}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vm}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sa}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sb}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sc}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@dl}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s2}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sh}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s1}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@mb}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mf}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mh}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mi}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@il}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mo}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ch}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cm}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cpf}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@c1}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cs}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % For linebreaks inside Verbatim environment from package fancyvrb. 
    \makeatletter
        \newbox\Wrappedcontinuationbox 
        \newbox\Wrappedvisiblespacebox 
        \newcommand*\Wrappedvisiblespace {\textcolor{red}{\textvisiblespace}} 
        \newcommand*\Wrappedcontinuationsymbol {\textcolor{red}{\llap{\tiny$\m@th\hookrightarrow$}}} 
        \newcommand*\Wrappedcontinuationindent {3ex } 
        \newcommand*\Wrappedafterbreak {\kern\Wrappedcontinuationindent\copy\Wrappedcontinuationbox} 
        % Take advantage of the already applied Pygments mark-up to insert 
        % potential linebreaks for TeX processing. 
        %        {, <, #, %, $, ' and ": go to next line. 
        %        _, }, ^, &, >, - and ~: stay at end of broken line. 
        % Use of \textquotesingle for straight quote. 
        \newcommand*\Wrappedbreaksatspecials {% 
            \def\PYGZus{\discretionary{\char`\_}{\Wrappedafterbreak}{\char`\_}}% 
            \def\PYGZob{\discretionary{}{\Wrappedafterbreak\char`\{}{\char`\{}}% 
            \def\PYGZcb{\discretionary{\char`\}}{\Wrappedafterbreak}{\char`\}}}% 
            \def\PYGZca{\discretionary{\char`\^}{\Wrappedafterbreak}{\char`\^}}% 
            \def\PYGZam{\discretionary{\char`\&}{\Wrappedafterbreak}{\char`\&}}% 
            \def\PYGZlt{\discretionary{}{\Wrappedafterbreak\char`\<}{\char`\<}}% 
            \def\PYGZgt{\discretionary{\char`\>}{\Wrappedafterbreak}{\char`\>}}% 
            \def\PYGZsh{\discretionary{}{\Wrappedafterbreak\char`\#}{\char`\#}}% 
            \def\PYGZpc{\discretionary{}{\Wrappedafterbreak\char`\%}{\char`\%}}% 
            \def\PYGZdl{\discretionary{}{\Wrappedafterbreak\char`\$}{\char`\$}}% 
            \def\PYGZhy{\discretionary{\char`\-}{\Wrappedafterbreak}{\char`\-}}% 
            \def\PYGZsq{\discretionary{}{\Wrappedafterbreak\textquotesingle}{\textquotesingle}}% 
            \def\PYGZdq{\discretionary{}{\Wrappedafterbreak\char`\"}{\char`\"}}% 
            \def\PYGZti{\discretionary{\char`\~}{\Wrappedafterbreak}{\char`\~}}% 
        } 
        % Some characters . , ; ? ! / are not pygmentized. 
        % This macro makes them "active" and they will insert potential linebreaks 
        \newcommand*\Wrappedbreaksatpunct {% 
            \lccode`\~`\.\lowercase{\def~}{\discretionary{\hbox{\char`\.}}{\Wrappedafterbreak}{\hbox{\char`\.}}}% 
            \lccode`\~`\,\lowercase{\def~}{\discretionary{\hbox{\char`\,}}{\Wrappedafterbreak}{\hbox{\char`\,}}}% 
            \lccode`\~`\;\lowercase{\def~}{\discretionary{\hbox{\char`\;}}{\Wrappedafterbreak}{\hbox{\char`\;}}}% 
            \lccode`\~`\:\lowercase{\def~}{\discretionary{\hbox{\char`\:}}{\Wrappedafterbreak}{\hbox{\char`\:}}}% 
            \lccode`\~`\?\lowercase{\def~}{\discretionary{\hbox{\char`\?}}{\Wrappedafterbreak}{\hbox{\char`\?}}}% 
            \lccode`\~`\!\lowercase{\def~}{\discretionary{\hbox{\char`\!}}{\Wrappedafterbreak}{\hbox{\char`\!}}}% 
            \lccode`\~`\/\lowercase{\def~}{\discretionary{\hbox{\char`\/}}{\Wrappedafterbreak}{\hbox{\char`\/}}}% 
            \catcode`\.\active
            \catcode`\,\active 
            \catcode`\;\active
            \catcode`\:\active
            \catcode`\?\active
            \catcode`\!\active
            \catcode`\/\active 
            \lccode`\~`\~ 	
        }
    \makeatother

    \let\OriginalVerbatim=\Verbatim
    \makeatletter
    \renewcommand{\Verbatim}[1][1]{%
        %\parskip\z@skip
        \sbox\Wrappedcontinuationbox {\Wrappedcontinuationsymbol}%
        \sbox\Wrappedvisiblespacebox {\FV@SetupFont\Wrappedvisiblespace}%
        \def\FancyVerbFormatLine ##1{\hsize\linewidth
            \vtop{\raggedright\hyphenpenalty\z@\exhyphenpenalty\z@
                \doublehyphendemerits\z@\finalhyphendemerits\z@
                \strut ##1\strut}%
        }%
        % If the linebreak is at a space, the latter will be displayed as visible
        % space at end of first line, and a continuation symbol starts next line.
        % Stretch/shrink are however usually zero for typewriter font.
        \def\FV@Space {%
            \nobreak\hskip\z@ plus\fontdimen3\font minus\fontdimen4\font
            \discretionary{\copy\Wrappedvisiblespacebox}{\Wrappedafterbreak}
            {\kern\fontdimen2\font}%
        }%
        
        % Allow breaks at special characters using \PYG... macros.
        \Wrappedbreaksatspecials
        % Breaks at punctuation characters . , ; ? ! and / need catcode=\active 	
        \OriginalVerbatim[#1,codes*=\Wrappedbreaksatpunct]%
    }
    \makeatother

    % Exact colors from NB
    \definecolor{incolor}{HTML}{303F9F}
    \definecolor{outcolor}{HTML}{D84315}
    \definecolor{cellborder}{HTML}{CFCFCF}
    \definecolor{cellbackground}{HTML}{F7F7F7}
    
    % prompt
    \makeatletter
    \newcommand{\boxspacing}{\kern\kvtcb@left@rule\kern\kvtcb@boxsep}
    \makeatother
    \newcommand{\prompt}[4]{
        {\ttfamily\llap{{\color{#2}[#3]:\hspace{3pt}#4}}\vspace{-\baselineskip}}
    }
    

    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}

    \title{\huge{\textbf{ Machine learning \& Deep learning Assignment}} \\
    \LARGE{M.Sc Part II Computer Science}}
    \author{Mithun Parab 509}
    

\begin{document}
    
\pagenumbering{roman} % Start roman numbering
\clearpage\maketitle
\thispagestyle{empty}
\begin{center}
    \begin{figure}[h]
        \centering
        \includegraphics[width=7cm]{RJCLG.png}
        %\caption{Your caption here}
        \label{fig:logo}
    \end{figure}

    \large{R.J. College of Arts, Science \& Commerce \\
    Machine learning \& Deep learning\\
    Seat number: 509
    }
\end{center}
% \newpage
% \include{certificate}
\newpage
\tableofcontents
\begin{center}
    Link for \href{https://github.com/Mithunprb/MSc-Practicals-Journals/tree/main/MSc-Part2/MLDL/Assignment}{GitHub} or \href{https://colab.research.google.com/drive/13JoWjWJP8VqKBViF47vz_JWEHe3Xk8VG?usp=sharing}{ Google Colab}
\end{center}
\newpage
\pagenumbering{arabic} % Start roman numbering
    
    \hypertarget{mldl-assignment-design-a-classifier-using-cnn}{%
\section{MLDL Assignment: Design a classifier using
CNN}\label{mldl-assignment-design-a-classifier-using-cnn}}

\hypertarget{introduction}{%
\subsection{Introduction:}\label{introduction}}

In the realm of modern machine learning, Convolutional Neural Networks
(CNNs) stand as a cornerstone of image classification. These networks
are designed to replicate the visual recognition abilities of humans by
employing specialized layers that can learn and identify intricate
patterns within images. This assignment delves into the development of a
classifier through the implementation of a CNN architecture.

    \hypertarget{import-packages}{%
\subsection{Import packages}\label{import-packages}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{1}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{tensorflow}\PY{n+nn}{.}\PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{utils} \PY{k+kn}{import} \PY{n}{to\PYZus{}categorical}
\PY{k+kn}{from} \PY{n+nn}{tensorflow}\PY{n+nn}{.}\PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{models} \PY{k+kn}{import} \PY{n}{Sequential}
\PY{k+kn}{from} \PY{n+nn}{tensorflow}\PY{n+nn}{.}\PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers} \PY{k+kn}{import} \PY{p}{(}
    \PY{n}{Conv2D}\PY{p}{,}
    \PY{n}{MaxPool2D}\PY{p}{,}
    \PY{n}{Dense}\PY{p}{,}
    \PY{n}{Flatten}\PY{p}{,}
    \PY{n}{Dropout}\PY{p}{,}
    \PY{n}{Conv2D}\PY{p}{,}
    \PY{n}{BatchNormalization}\PY{p}{,}
\PY{p}{)}
\PY{k+kn}{from} \PY{n+nn}{tensorflow}\PY{n+nn}{.}\PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{preprocessing}\PY{n+nn}{.}\PY{n+nn}{image} \PY{k+kn}{import} \PY{n}{ImageDataGenerator}
\PY{k+kn}{from} \PY{n+nn}{tensorflow}\PY{n+nn}{.}\PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{datasets} \PY{k+kn}{import} \PY{n}{cifar10}
\PY{k+kn}{import} \PY{n+nn}{tensorflow} \PY{k}{as} \PY{n+nn}{tf}
\PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
\PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
\PY{k+kn}{import} \PY{n+nn}{cv2}

\PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
/opt/conda/lib/python3.10/site-packages/scipy/\_\_init\_\_.py:146: UserWarning: A
NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy
(detected version 1.23.5
  warnings.warn(f"A NumPy version >=\{np\_minversion\} and <\{np\_maxversion\}"
/opt/conda/lib/python3.10/site-packages/tensorflow\_io/python/ops/\_\_init\_\_.py:98:
UserWarning: unable to load libtensorflow\_io\_plugins.so: unable to open file:
libtensorflow\_io\_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-
packages/tensorflow\_io/python/ops/libtensorflow\_io\_plugins.so']
caused by: ['/opt/conda/lib/python3.10/site-
packages/tensorflow\_io/python/ops/libtensorflow\_io\_plugins.so: undefined symbol:
\_ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic\_string\_viewIcSt11char\_traits
IcEENS\_14SourceLocationE']
  warnings.warn(f"unable to load libtensorflow\_io\_plugins.so: \{e\}")
/opt/conda/lib/python3.10/site-
packages/tensorflow\_io/python/ops/\_\_init\_\_.py:104: UserWarning: file system
plugins are not loaded: unable to open file: libtensorflow\_io.so, from paths:
['/opt/conda/lib/python3.10/site-
packages/tensorflow\_io/python/ops/libtensorflow\_io.so']
caused by: ['/opt/conda/lib/python3.10/site-
packages/tensorflow\_io/python/ops/libtensorflow\_io.so: undefined symbol:
\_ZTVN10tensorflow13GcsFileSystemE']
  warnings.warn(f"file system plugins are not loaded: \{e\}")
    \end{Verbatim}

    \hypertarget{normalization-and-one-hot-encoding}{%
\subsection{Normalization and One hot
encoding}\label{normalization-and-one-hot-encoding}}

Since our data is ready we now need to normalize the data, since
normalizing the images in deep learning will produce very good results.
Normalizing means we are bringing all the values in the data into a
common scale 0-1. This will make out model converge fast and also we
will not have any distrotions in the data.

For normalizing the pixel data (Image) we can simply divide the whole
pixel values with 255 since pixel values ranges from 0-255. So if we
divide them with 255 we automatically normalizee the data between 0-1.

\hypertarget{one-hot-encoding.}{%
\subsubsection{One hot encoding.}\label{one-hot-encoding.}}

CIFAR 10 has 10 categories, in general we should label the categorical
data using the one hot encoding.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{2}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{n}{x\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{)} \PY{o}{=} \PY{n}{cifar10}\PY{o}{.}\PY{n}{load\PYZus{}data}\PY{p}{(}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Shape of x\PYZus{}train is }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Shape of x\PYZus{}test is }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{x\PYZus{}test}\PY{o}{.}\PY{n}{shape}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Shape of y\PYZus{}train is }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Shape of y\PYZus{}test is }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{o}{.}\PY{n}{shape}\PY{p}{)}\PY{p}{)}
\PY{c+c1}{\PYZsh{} Normalizing}
\PY{n}{x\PYZus{}train} \PY{o}{=} \PY{n}{x\PYZus{}train} \PY{o}{/} \PY{l+m+mi}{255}
\PY{n}{x\PYZus{}test} \PY{o}{=} \PY{n}{x\PYZus{}test} \PY{o}{/} \PY{l+m+mi}{255}

\PY{c+c1}{\PYZsh{} One hot encoding}
\PY{n}{y\PYZus{}train\PYZus{}cat} \PY{o}{=} \PY{n}{to\PYZus{}categorical}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{)}
\PY{n}{y\PYZus{}test\PYZus{}cat} \PY{o}{=} \PY{n}{to\PYZus{}categorical}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Downloading data from https://www.cs.toronto.edu/\textasciitilde{}kriz/cifar-10-python.tar.gz
170498071/170498071 [==============================] - 6s 0us/step
Shape of x\_train is (50000, 32, 32, 3)
Shape of x\_test is (10000, 32, 32, 3)
Shape of y\_train is (50000, 1)
Shape of y\_test is (10000, 1)
    \end{Verbatim}

    \hypertarget{build-cnn-model}{%
\subsection{Build CNN Model}\label{build-cnn-model}}

Lets try to train a basic deep learning model. Any deep learning model
that needs to classify images use Convolution neural network (CNN).
CNN's are proven very effective on image data, also if we have enough
data, we can make a deep neural network with multiple CNN layers
arranged in specific design to create state of the art results.

I will start with two basic CNN layers, where each layer is attached to
a maxpool layer. Max pooling is a great way to reduce the size of
parameters without losing much information. As usual in any deep
learning model, I need to flatten the intermediate layer results and
pass them to a Dense network. Then the dense network result will be
passed to a final output layer where the number of units represents the
number of categories in the data, which is 10 in our case. Softmax is
chosen as the final activation because we need the highest probable
class out of 10.

Finally compile your model using adam optimizer.

Let us try to Sequentially build our models.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{3}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{model} \PY{o}{=} \PY{n}{Sequential}\PY{p}{(}\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}
    \PY{n}{Conv2D}\PY{p}{(}
        \PY{l+m+mi}{32}\PY{p}{,}
        \PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}\PY{p}{,}
        \PY{n}{activation}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{relu}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
        \PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{he\PYZus{}uniform}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
        \PY{n}{padding}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{same}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
        \PY{n}{input\PYZus{}shape}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{32}\PY{p}{,} \PY{l+m+mi}{32}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}\PY{p}{,}
    \PY{p}{)}
\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{BatchNormalization}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}
    \PY{n}{Conv2D}\PY{p}{(}
        \PY{l+m+mi}{32}\PY{p}{,} \PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{relu}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{he\PYZus{}uniform}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{same}\PY{l+s+s2}{\PYZdq{}}
    \PY{p}{)}
\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{BatchNormalization}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{MaxPool2D}\PY{p}{(}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{l+m+mf}{0.2}\PY{p}{)}\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}
    \PY{n}{Conv2D}\PY{p}{(}
        \PY{l+m+mi}{64}\PY{p}{,} \PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{relu}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{he\PYZus{}uniform}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{same}\PY{l+s+s2}{\PYZdq{}}
    \PY{p}{)}
\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{BatchNormalization}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}
    \PY{n}{Conv2D}\PY{p}{(}
        \PY{l+m+mi}{64}\PY{p}{,} \PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{relu}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{he\PYZus{}uniform}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{same}\PY{l+s+s2}{\PYZdq{}}
    \PY{p}{)}
\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{BatchNormalization}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{MaxPool2D}\PY{p}{(}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{l+m+mf}{0.3}\PY{p}{)}\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}
    \PY{n}{Conv2D}\PY{p}{(}
        \PY{l+m+mi}{128}\PY{p}{,} \PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{relu}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{he\PYZus{}uniform}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{same}\PY{l+s+s2}{\PYZdq{}}
    \PY{p}{)}
\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{BatchNormalization}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}
    \PY{n}{Conv2D}\PY{p}{(}
        \PY{l+m+mi}{128}\PY{p}{,} \PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{relu}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{he\PYZus{}uniform}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{same}\PY{l+s+s2}{\PYZdq{}}
    \PY{p}{)}
\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{BatchNormalization}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{MaxPool2D}\PY{p}{(}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{l+m+mf}{0.4}\PY{p}{)}\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Flatten}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{128}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{relu}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{he\PYZus{}uniform}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{BatchNormalization}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{l+m+mf}{0.5}\PY{p}{)}\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{softmax}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{compile-cnn}{%
\subsection{Compile CNN}\label{compile-cnn}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{4}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} compile model}
\PY{n}{model}\PY{o}{.}\PY{n}{compile}\PY{p}{(}\PY{n}{optimizer}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{adam}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{loss}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{categorical\PYZus{}crossentropy}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{metrics}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{accuracy}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Model: "sequential"
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
 Layer (type)                Output Shape              Param \#
=================================================================
 conv2d (Conv2D)             (None, 32, 32, 32)        896

 batch\_normalization (BatchN  (None, 32, 32, 32)       128
 ormalization)

 conv2d\_1 (Conv2D)           (None, 32, 32, 32)        9248

 batch\_normalization\_1 (Batc  (None, 32, 32, 32)       128
 hNormalization)

 max\_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0
 )

 dropout (Dropout)           (None, 16, 16, 32)        0

 conv2d\_2 (Conv2D)           (None, 16, 16, 64)        18496

 batch\_normalization\_2 (Batc  (None, 16, 16, 64)       256
 hNormalization)

 conv2d\_3 (Conv2D)           (None, 16, 16, 64)        36928

 batch\_normalization\_3 (Batc  (None, 16, 16, 64)       256
 hNormalization)

 max\_pooling2d\_1 (MaxPooling  (None, 8, 8, 64)         0
 2D)

 dropout\_1 (Dropout)         (None, 8, 8, 64)          0

 conv2d\_4 (Conv2D)           (None, 8, 8, 128)         73856

 batch\_normalization\_4 (Batc  (None, 8, 8, 128)        512
 hNormalization)

 conv2d\_5 (Conv2D)           (None, 8, 8, 128)         147584

 batch\_normalization\_5 (Batc  (None, 8, 8, 128)        512
 hNormalization)

 max\_pooling2d\_2 (MaxPooling  (None, 4, 4, 128)        0
 2D)

 dropout\_2 (Dropout)         (None, 4, 4, 128)         0

 flatten (Flatten)           (None, 2048)              0

 dense (Dense)               (None, 128)               262272

 batch\_normalization\_6 (Batc  (None, 128)              512
 hNormalization)

 dropout\_3 (Dropout)         (None, 128)               0

 dense\_1 (Dense)             (None, 10)                1290

=================================================================
Total params: 552,874
Trainable params: 551,722
Non-trainable params: 1,152
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{5}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{tf}\PY{o}{.}\PY{n}{keras}\PY{o}{.}\PY{n}{utils}\PY{o}{.}\PY{n}{plot\PYZus{}model}\PY{p}{(}
    \PY{n}{model}\PY{p}{,}
    \PY{n}{to\PYZus{}file}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{model.png}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
    \PY{n}{show\PYZus{}shapes}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}
    \PY{n}{show\PYZus{}layer\PYZus{}names}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}
    \PY{n}{expand\PYZus{}nested}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,}
\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}
 
            
\prompt{Out}{outcolor}{5}{}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_10_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{6}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Image Data Generator , we are shifting image accross width and height also we are flipping the image horizantally.}
\PY{n}{datagen} \PY{o}{=} \PY{n}{ImageDataGenerator}\PY{p}{(}
    \PY{n}{width\PYZus{}shift\PYZus{}range}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{,}
    \PY{n}{height\PYZus{}shift\PYZus{}range}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{,}
    \PY{n}{horizontal\PYZus{}flip}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}
    \PY{n}{rotation\PYZus{}range}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{,}
\PY{p}{)}

\PY{n}{it\PYZus{}train} \PY{o}{=} \PY{n}{datagen}\PY{o}{.}\PY{n}{flow}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train\PYZus{}cat}\PY{p}{)}

\PY{n}{steps} \PY{o}{=} \PY{n+nb}{int}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{/} \PY{l+m+mi}{64}\PY{p}{)}
\PY{n}{num\PYZus{}epochs} \PY{o}{=} \PY{l+m+mi}{200}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{training-cnn}{%
\subsection{Training CNN}\label{training-cnn}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{7}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Fit the model on the batches generated by datagen.flow().}
\PY{n}{history} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}
    \PY{n}{it\PYZus{}train}\PY{p}{,}
    \PY{n}{epochs}\PY{o}{=}\PY{n}{num\PYZus{}epochs}\PY{p}{,}
    \PY{n}{steps\PYZus{}per\PYZus{}epoch}\PY{o}{=}\PY{n}{steps}\PY{p}{,}
    \PY{n}{validation\PYZus{}data}\PY{o}{=}\PY{p}{(}\PY{n}{x\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test\PYZus{}cat}\PY{p}{)}\PY{p}{,}
    \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,}
\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Epoch 1/200
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
2023-08-17 13:59:38.315391: E
tensorflow/core/grappler/optimizers/meta\_optimizer.cc:954] layout failed:
INVALID\_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin
shape insequential/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-
LayoutOptimizer
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
781/781 - 31s - loss: 2.0085 - accuracy: 0.3215 - val\_loss: 1.4300 -
val\_accuracy: 0.4833 - 31s/epoch - 40ms/step
Epoch 2/200
781/781 - 18s - loss: 1.5154 - accuracy: 0.4527 - val\_loss: 1.2820 -
val\_accuracy: 0.5439 - 18s/epoch - 23ms/step
Epoch 3/200
781/781 - 19s - loss: 1.3728 - accuracy: 0.5029 - val\_loss: 1.2241 -
val\_accuracy: 0.5710 - 19s/epoch - 24ms/step
Epoch 4/200
781/781 - 19s - loss: 1.2819 - accuracy: 0.5436 - val\_loss: 1.2127 -
val\_accuracy: 0.5729 - 19s/epoch - 24ms/step
Epoch 5/200
781/781 - 18s - loss: 1.2246 - accuracy: 0.5671 - val\_loss: 1.1074 -
val\_accuracy: 0.6051 - 18s/epoch - 23ms/step
Epoch 6/200
781/781 - 19s - loss: 1.1618 - accuracy: 0.5908 - val\_loss: 0.9671 -
val\_accuracy: 0.6624 - 19s/epoch - 24ms/step
Epoch 7/200
781/781 - 18s - loss: 1.1089 - accuracy: 0.6082 - val\_loss: 1.0035 -
val\_accuracy: 0.6519 - 18s/epoch - 23ms/step
Epoch 8/200
781/781 - 18s - loss: 1.0683 - accuracy: 0.6294 - val\_loss: 0.8618 -
val\_accuracy: 0.7019 - 18s/epoch - 23ms/step
Epoch 9/200
781/781 - 17s - loss: 1.0277 - accuracy: 0.6404 - val\_loss: 0.9863 -
val\_accuracy: 0.6669 - 17s/epoch - 22ms/step
Epoch 10/200
781/781 - 17s - loss: 1.0042 - accuracy: 0.6494 - val\_loss: 1.0345 -
val\_accuracy: 0.6443 - 17s/epoch - 21ms/step
Epoch 11/200
781/781 - 18s - loss: 0.9858 - accuracy: 0.6576 - val\_loss: 0.9288 -
val\_accuracy: 0.6852 - 18s/epoch - 23ms/step
Epoch 12/200
781/781 - 17s - loss: 0.9604 - accuracy: 0.6701 - val\_loss: 0.9185 -
val\_accuracy: 0.6922 - 17s/epoch - 22ms/step
Epoch 13/200
781/781 - 17s - loss: 0.9303 - accuracy: 0.6799 - val\_loss: 0.8376 -
val\_accuracy: 0.7151 - 17s/epoch - 22ms/step
Epoch 14/200
781/781 - 17s - loss: 0.9136 - accuracy: 0.6849 - val\_loss: 0.8000 -
val\_accuracy: 0.7268 - 17s/epoch - 22ms/step
Epoch 15/200
781/781 - 17s - loss: 0.8933 - accuracy: 0.6928 - val\_loss: 0.7934 -
val\_accuracy: 0.7323 - 17s/epoch - 21ms/step
Epoch 16/200
781/781 - 17s - loss: 0.8792 - accuracy: 0.6975 - val\_loss: 0.7101 -
val\_accuracy: 0.7541 - 17s/epoch - 22ms/step
Epoch 17/200
781/781 - 17s - loss: 0.8779 - accuracy: 0.7002 - val\_loss: 0.8257 -
val\_accuracy: 0.7201 - 17s/epoch - 22ms/step
Epoch 18/200
781/781 - 17s - loss: 0.8573 - accuracy: 0.7072 - val\_loss: 0.7502 -
val\_accuracy: 0.7389 - 17s/epoch - 22ms/step
Epoch 19/200
781/781 - 17s - loss: 0.8483 - accuracy: 0.7085 - val\_loss: 0.6664 -
val\_accuracy: 0.7742 - 17s/epoch - 22ms/step
Epoch 20/200
781/781 - 17s - loss: 0.8253 - accuracy: 0.7135 - val\_loss: 0.7511 -
val\_accuracy: 0.7454 - 17s/epoch - 22ms/step
Epoch 21/200
781/781 - 18s - loss: 0.8176 - accuracy: 0.7190 - val\_loss: 0.7141 -
val\_accuracy: 0.7566 - 18s/epoch - 23ms/step
Epoch 22/200
781/781 - 17s - loss: 0.8188 - accuracy: 0.7172 - val\_loss: 0.7240 -
val\_accuracy: 0.7561 - 17s/epoch - 22ms/step
Epoch 23/200
781/781 - 18s - loss: 0.8144 - accuracy: 0.7222 - val\_loss: 0.6937 -
val\_accuracy: 0.7687 - 18s/epoch - 23ms/step
Epoch 24/200
781/781 - 18s - loss: 0.8033 - accuracy: 0.7233 - val\_loss: 0.7525 -
val\_accuracy: 0.7503 - 18s/epoch - 23ms/step
Epoch 25/200
781/781 - 17s - loss: 0.7955 - accuracy: 0.7309 - val\_loss: 0.6784 -
val\_accuracy: 0.7694 - 17s/epoch - 21ms/step
Epoch 26/200
781/781 - 18s - loss: 0.7928 - accuracy: 0.7291 - val\_loss: 0.7181 -
val\_accuracy: 0.7605 - 18s/epoch - 23ms/step
Epoch 27/200
781/781 - 17s - loss: 0.7727 - accuracy: 0.7365 - val\_loss: 0.6927 -
val\_accuracy: 0.7650 - 17s/epoch - 22ms/step
Epoch 28/200
781/781 - 18s - loss: 0.7745 - accuracy: 0.7354 - val\_loss: 0.6481 -
val\_accuracy: 0.7813 - 18s/epoch - 23ms/step
Epoch 29/200
781/781 - 18s - loss: 0.7757 - accuracy: 0.7387 - val\_loss: 0.6572 -
val\_accuracy: 0.7777 - 18s/epoch - 23ms/step
Epoch 30/200
781/781 - 17s - loss: 0.7655 - accuracy: 0.7403 - val\_loss: 0.6714 -
val\_accuracy: 0.7753 - 17s/epoch - 22ms/step
Epoch 31/200
781/781 - 18s - loss: 0.7525 - accuracy: 0.7414 - val\_loss: 0.6384 -
val\_accuracy: 0.7847 - 18s/epoch - 23ms/step
Epoch 32/200
781/781 - 17s - loss: 0.7480 - accuracy: 0.7467 - val\_loss: 0.6977 -
val\_accuracy: 0.7728 - 17s/epoch - 21ms/step
Epoch 33/200
781/781 - 18s - loss: 0.7551 - accuracy: 0.7437 - val\_loss: 0.5976 -
val\_accuracy: 0.7974 - 18s/epoch - 23ms/step
Epoch 34/200
781/781 - 18s - loss: 0.7433 - accuracy: 0.7461 - val\_loss: 0.7035 -
val\_accuracy: 0.7613 - 18s/epoch - 23ms/step
Epoch 35/200
781/781 - 17s - loss: 0.7494 - accuracy: 0.7448 - val\_loss: 0.6130 -
val\_accuracy: 0.7970 - 17s/epoch - 22ms/step
Epoch 36/200
781/781 - 17s - loss: 0.7297 - accuracy: 0.7515 - val\_loss: 0.6525 -
val\_accuracy: 0.7787 - 17s/epoch - 22ms/step
Epoch 37/200
781/781 - 16s - loss: 0.7317 - accuracy: 0.7494 - val\_loss: 0.6641 -
val\_accuracy: 0.7763 - 16s/epoch - 21ms/step
Epoch 38/200
781/781 - 17s - loss: 0.7307 - accuracy: 0.7502 - val\_loss: 0.5866 -
val\_accuracy: 0.7972 - 17s/epoch - 21ms/step
Epoch 39/200
781/781 - 17s - loss: 0.7145 - accuracy: 0.7562 - val\_loss: 0.6834 -
val\_accuracy: 0.7672 - 17s/epoch - 22ms/step
Epoch 40/200
781/781 - 17s - loss: 0.7248 - accuracy: 0.7536 - val\_loss: 0.6352 -
val\_accuracy: 0.7862 - 17s/epoch - 21ms/step
Epoch 41/200
781/781 - 18s - loss: 0.7226 - accuracy: 0.7521 - val\_loss: 0.6648 -
val\_accuracy: 0.7773 - 18s/epoch - 23ms/step
Epoch 42/200
781/781 - 17s - loss: 0.7028 - accuracy: 0.7602 - val\_loss: 0.6903 -
val\_accuracy: 0.7651 - 17s/epoch - 22ms/step
Epoch 43/200
781/781 - 17s - loss: 0.7137 - accuracy: 0.7568 - val\_loss: 0.5948 -
val\_accuracy: 0.7996 - 17s/epoch - 22ms/step
Epoch 44/200
781/781 - 18s - loss: 0.7034 - accuracy: 0.7613 - val\_loss: 0.6109 -
val\_accuracy: 0.7934 - 18s/epoch - 23ms/step
Epoch 45/200
781/781 - 17s - loss: 0.7100 - accuracy: 0.7568 - val\_loss: 0.6095 -
val\_accuracy: 0.7943 - 17s/epoch - 22ms/step
Epoch 46/200
781/781 - 17s - loss: 0.7056 - accuracy: 0.7593 - val\_loss: 0.6220 -
val\_accuracy: 0.7907 - 17s/epoch - 22ms/step
Epoch 47/200
781/781 - 17s - loss: 0.6900 - accuracy: 0.7622 - val\_loss: 0.5982 -
val\_accuracy: 0.8017 - 17s/epoch - 22ms/step
Epoch 48/200
781/781 - 17s - loss: 0.7076 - accuracy: 0.7621 - val\_loss: 0.5674 -
val\_accuracy: 0.8057 - 17s/epoch - 22ms/step
Epoch 49/200
781/781 - 17s - loss: 0.6923 - accuracy: 0.7666 - val\_loss: 0.6180 -
val\_accuracy: 0.7901 - 17s/epoch - 22ms/step
Epoch 50/200
781/781 - 16s - loss: 0.6932 - accuracy: 0.7605 - val\_loss: 0.6483 -
val\_accuracy: 0.7839 - 16s/epoch - 21ms/step
Epoch 51/200
781/781 - 18s - loss: 0.6815 - accuracy: 0.7663 - val\_loss: 0.5655 -
val\_accuracy: 0.8075 - 18s/epoch - 23ms/step
Epoch 52/200
781/781 - 17s - loss: 0.6896 - accuracy: 0.7650 - val\_loss: 0.6706 -
val\_accuracy: 0.7764 - 17s/epoch - 21ms/step
Epoch 53/200
781/781 - 18s - loss: 0.6790 - accuracy: 0.7680 - val\_loss: 0.5927 -
val\_accuracy: 0.8022 - 18s/epoch - 23ms/step
Epoch 54/200
781/781 - 17s - loss: 0.6769 - accuracy: 0.7688 - val\_loss: 0.6368 -
val\_accuracy: 0.7842 - 17s/epoch - 22ms/step
Epoch 55/200
781/781 - 17s - loss: 0.6672 - accuracy: 0.7741 - val\_loss: 0.5795 -
val\_accuracy: 0.8043 - 17s/epoch - 21ms/step
Epoch 56/200
781/781 - 17s - loss: 0.6753 - accuracy: 0.7723 - val\_loss: 0.5219 -
val\_accuracy: 0.8202 - 17s/epoch - 22ms/step
Epoch 57/200
781/781 - 17s - loss: 0.6710 - accuracy: 0.7720 - val\_loss: 0.5683 -
val\_accuracy: 0.8085 - 17s/epoch - 21ms/step
Epoch 58/200
781/781 - 18s - loss: 0.6616 - accuracy: 0.7725 - val\_loss: 0.5869 -
val\_accuracy: 0.8037 - 18s/epoch - 23ms/step
Epoch 59/200
781/781 - 17s - loss: 0.6606 - accuracy: 0.7741 - val\_loss: 0.5839 -
val\_accuracy: 0.8068 - 17s/epoch - 22ms/step
Epoch 60/200
781/781 - 17s - loss: 0.6748 - accuracy: 0.7731 - val\_loss: 0.6409 -
val\_accuracy: 0.7869 - 17s/epoch - 21ms/step
Epoch 61/200
781/781 - 17s - loss: 0.6461 - accuracy: 0.7800 - val\_loss: 0.6397 -
val\_accuracy: 0.7840 - 17s/epoch - 22ms/step
Epoch 62/200
781/781 - 17s - loss: 0.6604 - accuracy: 0.7740 - val\_loss: 0.5656 -
val\_accuracy: 0.8083 - 17s/epoch - 22ms/step
Epoch 63/200
781/781 - 17s - loss: 0.6671 - accuracy: 0.7744 - val\_loss: 0.5492 -
val\_accuracy: 0.8133 - 17s/epoch - 22ms/step
Epoch 64/200
781/781 - 17s - loss: 0.6520 - accuracy: 0.7773 - val\_loss: 0.5923 -
val\_accuracy: 0.8020 - 17s/epoch - 22ms/step
Epoch 65/200
781/781 - 18s - loss: 0.6577 - accuracy: 0.7743 - val\_loss: 0.6059 -
val\_accuracy: 0.7959 - 18s/epoch - 23ms/step
Epoch 66/200
781/781 - 17s - loss: 0.6474 - accuracy: 0.7801 - val\_loss: 0.5560 -
val\_accuracy: 0.8125 - 17s/epoch - 22ms/step
Epoch 67/200
781/781 - 17s - loss: 0.6544 - accuracy: 0.7792 - val\_loss: 0.5350 -
val\_accuracy: 0.8219 - 17s/epoch - 21ms/step
Epoch 68/200
781/781 - 18s - loss: 0.6513 - accuracy: 0.7778 - val\_loss: 0.6270 -
val\_accuracy: 0.7919 - 18s/epoch - 23ms/step
Epoch 69/200
781/781 - 17s - loss: 0.6490 - accuracy: 0.7778 - val\_loss: 0.4966 -
val\_accuracy: 0.8307 - 17s/epoch - 22ms/step
Epoch 70/200
781/781 - 18s - loss: 0.6420 - accuracy: 0.7824 - val\_loss: 0.5803 -
val\_accuracy: 0.8049 - 18s/epoch - 23ms/step
Epoch 71/200
781/781 - 17s - loss: 0.6393 - accuracy: 0.7828 - val\_loss: 0.6194 -
val\_accuracy: 0.7953 - 17s/epoch - 22ms/step
Epoch 72/200
781/781 - 17s - loss: 0.6356 - accuracy: 0.7843 - val\_loss: 0.5114 -
val\_accuracy: 0.8253 - 17s/epoch - 22ms/step
Epoch 73/200
781/781 - 17s - loss: 0.6352 - accuracy: 0.7852 - val\_loss: 0.5236 -
val\_accuracy: 0.8225 - 17s/epoch - 22ms/step
Epoch 74/200
781/781 - 17s - loss: 0.6304 - accuracy: 0.7870 - val\_loss: 0.5759 -
val\_accuracy: 0.8043 - 17s/epoch - 22ms/step
Epoch 75/200
781/781 - 18s - loss: 0.6319 - accuracy: 0.7845 - val\_loss: 0.5435 -
val\_accuracy: 0.8170 - 18s/epoch - 23ms/step
Epoch 76/200
781/781 - 17s - loss: 0.6329 - accuracy: 0.7855 - val\_loss: 0.5084 -
val\_accuracy: 0.8269 - 17s/epoch - 22ms/step
Epoch 77/200
781/781 - 17s - loss: 0.6310 - accuracy: 0.7832 - val\_loss: 0.5949 -
val\_accuracy: 0.7987 - 17s/epoch - 22ms/step
Epoch 78/200
781/781 - 17s - loss: 0.6277 - accuracy: 0.7870 - val\_loss: 0.5328 -
val\_accuracy: 0.8228 - 17s/epoch - 22ms/step
Epoch 79/200
781/781 - 17s - loss: 0.6314 - accuracy: 0.7862 - val\_loss: 0.5531 -
val\_accuracy: 0.8148 - 17s/epoch - 22ms/step
Epoch 80/200
781/781 - 18s - loss: 0.6337 - accuracy: 0.7866 - val\_loss: 0.4871 -
val\_accuracy: 0.8328 - 18s/epoch - 23ms/step
Epoch 81/200
781/781 - 17s - loss: 0.6254 - accuracy: 0.7881 - val\_loss: 0.5451 -
val\_accuracy: 0.8200 - 17s/epoch - 21ms/step
Epoch 82/200
781/781 - 18s - loss: 0.6349 - accuracy: 0.7843 - val\_loss: 0.5630 -
val\_accuracy: 0.8100 - 18s/epoch - 23ms/step
Epoch 83/200
781/781 - 17s - loss: 0.6306 - accuracy: 0.7850 - val\_loss: 0.5192 -
val\_accuracy: 0.8241 - 17s/epoch - 21ms/step
Epoch 84/200
781/781 - 18s - loss: 0.6148 - accuracy: 0.7900 - val\_loss: 0.5285 -
val\_accuracy: 0.8243 - 18s/epoch - 23ms/step
Epoch 85/200
781/781 - 17s - loss: 0.6221 - accuracy: 0.7890 - val\_loss: 0.5135 -
val\_accuracy: 0.8264 - 17s/epoch - 22ms/step
Epoch 86/200
781/781 - 17s - loss: 0.6136 - accuracy: 0.7916 - val\_loss: 0.6065 -
val\_accuracy: 0.7976 - 17s/epoch - 21ms/step
Epoch 87/200
781/781 - 18s - loss: 0.6201 - accuracy: 0.7909 - val\_loss: 0.5226 -
val\_accuracy: 0.8212 - 18s/epoch - 23ms/step
Epoch 88/200
781/781 - 17s - loss: 0.6189 - accuracy: 0.7901 - val\_loss: 0.5095 -
val\_accuracy: 0.8282 - 17s/epoch - 21ms/step
Epoch 89/200
781/781 - 18s - loss: 0.6191 - accuracy: 0.7881 - val\_loss: 0.5392 -
val\_accuracy: 0.8170 - 18s/epoch - 23ms/step
Epoch 90/200
781/781 - 17s - loss: 0.6184 - accuracy: 0.7873 - val\_loss: 0.5210 -
val\_accuracy: 0.8247 - 17s/epoch - 22ms/step
Epoch 91/200
781/781 - 17s - loss: 0.6155 - accuracy: 0.7878 - val\_loss: 0.5725 -
val\_accuracy: 0.8102 - 17s/epoch - 22ms/step
Epoch 92/200
781/781 - 18s - loss: 0.6148 - accuracy: 0.7911 - val\_loss: 0.5373 -
val\_accuracy: 0.8227 - 18s/epoch - 23ms/step
Epoch 93/200
781/781 - 16s - loss: 0.6144 - accuracy: 0.7908 - val\_loss: 0.4847 -
val\_accuracy: 0.8343 - 16s/epoch - 21ms/step
Epoch 94/200
781/781 - 17s - loss: 0.6106 - accuracy: 0.7910 - val\_loss: 0.5485 -
val\_accuracy: 0.8175 - 17s/epoch - 22ms/step
Epoch 95/200
781/781 - 17s - loss: 0.5982 - accuracy: 0.7962 - val\_loss: 0.5968 -
val\_accuracy: 0.8056 - 17s/epoch - 22ms/step
Epoch 96/200
781/781 - 17s - loss: 0.6072 - accuracy: 0.7945 - val\_loss: 0.5416 -
val\_accuracy: 0.8201 - 17s/epoch - 22ms/step
Epoch 97/200
781/781 - 17s - loss: 0.6021 - accuracy: 0.7953 - val\_loss: 0.5162 -
val\_accuracy: 0.8249 - 17s/epoch - 22ms/step
Epoch 98/200
781/781 - 17s - loss: 0.6173 - accuracy: 0.7912 - val\_loss: 0.4936 -
val\_accuracy: 0.8364 - 17s/epoch - 22ms/step
Epoch 99/200
781/781 - 18s - loss: 0.6018 - accuracy: 0.7965 - val\_loss: 0.5676 -
val\_accuracy: 0.8113 - 18s/epoch - 23ms/step
Epoch 100/200
781/781 - 17s - loss: 0.6019 - accuracy: 0.7967 - val\_loss: 0.5425 -
val\_accuracy: 0.8181 - 17s/epoch - 21ms/step
Epoch 101/200
781/781 - 18s - loss: 0.5995 - accuracy: 0.7958 - val\_loss: 0.5538 -
val\_accuracy: 0.8157 - 18s/epoch - 23ms/step
Epoch 102/200
781/781 - 17s - loss: 0.6110 - accuracy: 0.7928 - val\_loss: 0.5077 -
val\_accuracy: 0.8270 - 17s/epoch - 22ms/step
Epoch 103/200
781/781 - 17s - loss: 0.6008 - accuracy: 0.7961 - val\_loss: 0.5326 -
val\_accuracy: 0.8202 - 17s/epoch - 22ms/step
Epoch 104/200
781/781 - 17s - loss: 0.6080 - accuracy: 0.7930 - val\_loss: 0.5338 -
val\_accuracy: 0.8208 - 17s/epoch - 22ms/step
Epoch 105/200
781/781 - 18s - loss: 0.5984 - accuracy: 0.7974 - val\_loss: 0.4947 -
val\_accuracy: 0.8338 - 18s/epoch - 23ms/step
Epoch 106/200
781/781 - 18s - loss: 0.5931 - accuracy: 0.7992 - val\_loss: 0.5096 -
val\_accuracy: 0.8259 - 18s/epoch - 22ms/step
Epoch 107/200
781/781 - 17s - loss: 0.6033 - accuracy: 0.7919 - val\_loss: 0.4699 -
val\_accuracy: 0.8408 - 17s/epoch - 22ms/step
Epoch 108/200
781/781 - 18s - loss: 0.5951 - accuracy: 0.7981 - val\_loss: 0.5593 -
val\_accuracy: 0.8164 - 18s/epoch - 23ms/step
Epoch 109/200
781/781 - 18s - loss: 0.6076 - accuracy: 0.7963 - val\_loss: 0.5190 -
val\_accuracy: 0.8248 - 18s/epoch - 23ms/step
Epoch 110/200
781/781 - 19s - loss: 0.6091 - accuracy: 0.7925 - val\_loss: 0.5110 -
val\_accuracy: 0.8275 - 19s/epoch - 24ms/step
Epoch 111/200
781/781 - 18s - loss: 0.5941 - accuracy: 0.7978 - val\_loss: 0.5041 -
val\_accuracy: 0.8285 - 18s/epoch - 23ms/step
Epoch 112/200
781/781 - 18s - loss: 0.5903 - accuracy: 0.8029 - val\_loss: 0.5166 -
val\_accuracy: 0.8275 - 18s/epoch - 23ms/step
Epoch 113/200
781/781 - 18s - loss: 0.5870 - accuracy: 0.8029 - val\_loss: 0.4917 -
val\_accuracy: 0.8345 - 18s/epoch - 23ms/step
Epoch 114/200
781/781 - 17s - loss: 0.5926 - accuracy: 0.7981 - val\_loss: 0.5179 -
val\_accuracy: 0.8240 - 17s/epoch - 22ms/step
Epoch 115/200
781/781 - 18s - loss: 0.5900 - accuracy: 0.8005 - val\_loss: 0.5250 -
val\_accuracy: 0.8251 - 18s/epoch - 23ms/step
Epoch 116/200
781/781 - 18s - loss: 0.5955 - accuracy: 0.8003 - val\_loss: 0.5351 -
val\_accuracy: 0.8178 - 18s/epoch - 22ms/step
Epoch 117/200
781/781 - 18s - loss: 0.5914 - accuracy: 0.8004 - val\_loss: 0.5631 -
val\_accuracy: 0.8141 - 18s/epoch - 24ms/step
Epoch 118/200
781/781 - 18s - loss: 0.5948 - accuracy: 0.7993 - val\_loss: 0.5212 -
val\_accuracy: 0.8271 - 18s/epoch - 22ms/step
Epoch 119/200
781/781 - 19s - loss: 0.5850 - accuracy: 0.8022 - val\_loss: 0.5072 -
val\_accuracy: 0.8251 - 19s/epoch - 24ms/step
Epoch 120/200
781/781 - 19s - loss: 0.5975 - accuracy: 0.7977 - val\_loss: 0.4905 -
val\_accuracy: 0.8336 - 19s/epoch - 24ms/step
Epoch 121/200
781/781 - 17s - loss: 0.5835 - accuracy: 0.8030 - val\_loss: 0.4544 -
val\_accuracy: 0.8436 - 17s/epoch - 22ms/step
Epoch 122/200
781/781 - 19s - loss: 0.5894 - accuracy: 0.8007 - val\_loss: 0.4836 -
val\_accuracy: 0.8373 - 19s/epoch - 24ms/step
Epoch 123/200
781/781 - 18s - loss: 0.5859 - accuracy: 0.8011 - val\_loss: 0.5485 -
val\_accuracy: 0.8168 - 18s/epoch - 23ms/step
Epoch 124/200
781/781 - 18s - loss: 0.5829 - accuracy: 0.8031 - val\_loss: 0.5740 -
val\_accuracy: 0.8062 - 18s/epoch - 23ms/step
Epoch 125/200
781/781 - 19s - loss: 0.5763 - accuracy: 0.8049 - val\_loss: 0.5329 -
val\_accuracy: 0.8228 - 19s/epoch - 24ms/step
Epoch 126/200
781/781 - 18s - loss: 0.5968 - accuracy: 0.7961 - val\_loss: 0.5344 -
val\_accuracy: 0.8198 - 18s/epoch - 22ms/step
Epoch 127/200
781/781 - 18s - loss: 0.5830 - accuracy: 0.8029 - val\_loss: 0.5240 -
val\_accuracy: 0.8244 - 18s/epoch - 24ms/step
Epoch 128/200
781/781 - 17s - loss: 0.5773 - accuracy: 0.8028 - val\_loss: 0.4743 -
val\_accuracy: 0.8397 - 17s/epoch - 22ms/step
Epoch 129/200
781/781 - 18s - loss: 0.5782 - accuracy: 0.8026 - val\_loss: 0.5885 -
val\_accuracy: 0.7990 - 18s/epoch - 23ms/step
Epoch 130/200
781/781 - 17s - loss: 0.5761 - accuracy: 0.8016 - val\_loss: 0.5289 -
val\_accuracy: 0.8225 - 17s/epoch - 22ms/step
Epoch 131/200
781/781 - 18s - loss: 0.5775 - accuracy: 0.8032 - val\_loss: 0.4896 -
val\_accuracy: 0.8338 - 18s/epoch - 23ms/step
Epoch 132/200
781/781 - 18s - loss: 0.5774 - accuracy: 0.8047 - val\_loss: 0.4770 -
val\_accuracy: 0.8365 - 18s/epoch - 24ms/step
Epoch 133/200
781/781 - 17s - loss: 0.5677 - accuracy: 0.8055 - val\_loss: 0.4673 -
val\_accuracy: 0.8393 - 17s/epoch - 22ms/step
Epoch 134/200
781/781 - 18s - loss: 0.5637 - accuracy: 0.8091 - val\_loss: 0.4801 -
val\_accuracy: 0.8373 - 18s/epoch - 23ms/step
Epoch 135/200
781/781 - 18s - loss: 0.5698 - accuracy: 0.8075 - val\_loss: 0.5211 -
val\_accuracy: 0.8257 - 18s/epoch - 23ms/step
Epoch 136/200
781/781 - 18s - loss: 0.5701 - accuracy: 0.8036 - val\_loss: 0.5058 -
val\_accuracy: 0.8334 - 18s/epoch - 23ms/step
Epoch 137/200
781/781 - 18s - loss: 0.5677 - accuracy: 0.8062 - val\_loss: 0.5012 -
val\_accuracy: 0.8318 - 18s/epoch - 23ms/step
Epoch 138/200
781/781 - 18s - loss: 0.5683 - accuracy: 0.8064 - val\_loss: 0.5459 -
val\_accuracy: 0.8148 - 18s/epoch - 23ms/step
Epoch 139/200
781/781 - 18s - loss: 0.5791 - accuracy: 0.8047 - val\_loss: 0.5002 -
val\_accuracy: 0.8311 - 18s/epoch - 23ms/step
Epoch 140/200
781/781 - 19s - loss: 0.5708 - accuracy: 0.8062 - val\_loss: 0.4597 -
val\_accuracy: 0.8436 - 19s/epoch - 24ms/step
Epoch 141/200
781/781 - 18s - loss: 0.5726 - accuracy: 0.8054 - val\_loss: 0.5119 -
val\_accuracy: 0.8279 - 18s/epoch - 23ms/step
Epoch 142/200
781/781 - 18s - loss: 0.5684 - accuracy: 0.8053 - val\_loss: 0.4959 -
val\_accuracy: 0.8313 - 18s/epoch - 23ms/step
Epoch 143/200
781/781 - 18s - loss: 0.5602 - accuracy: 0.8112 - val\_loss: 0.4949 -
val\_accuracy: 0.8332 - 18s/epoch - 23ms/step
Epoch 144/200
781/781 - 19s - loss: 0.5724 - accuracy: 0.8069 - val\_loss: 0.4558 -
val\_accuracy: 0.8454 - 19s/epoch - 24ms/step
Epoch 145/200
781/781 - 18s - loss: 0.5739 - accuracy: 0.8076 - val\_loss: 0.4472 -
val\_accuracy: 0.8491 - 18s/epoch - 22ms/step
Epoch 146/200
781/781 - 17s - loss: 0.5692 - accuracy: 0.8075 - val\_loss: 0.4648 -
val\_accuracy: 0.8433 - 17s/epoch - 22ms/step
Epoch 147/200
781/781 - 18s - loss: 0.5610 - accuracy: 0.8115 - val\_loss: 0.4796 -
val\_accuracy: 0.8397 - 18s/epoch - 24ms/step
Epoch 148/200
781/781 - 18s - loss: 0.5743 - accuracy: 0.8048 - val\_loss: 0.4867 -
val\_accuracy: 0.8355 - 18s/epoch - 22ms/step
Epoch 149/200
781/781 - 18s - loss: 0.5686 - accuracy: 0.8091 - val\_loss: 0.4427 -
val\_accuracy: 0.8499 - 18s/epoch - 24ms/step
Epoch 150/200
781/781 - 18s - loss: 0.5702 - accuracy: 0.8068 - val\_loss: 0.4938 -
val\_accuracy: 0.8374 - 18s/epoch - 23ms/step
Epoch 151/200
781/781 - 18s - loss: 0.5626 - accuracy: 0.8087 - val\_loss: 0.5088 -
val\_accuracy: 0.8310 - 18s/epoch - 23ms/step
Epoch 152/200
781/781 - 18s - loss: 0.5721 - accuracy: 0.8047 - val\_loss: 0.5268 -
val\_accuracy: 0.8263 - 18s/epoch - 23ms/step
Epoch 153/200
781/781 - 18s - loss: 0.5628 - accuracy: 0.8099 - val\_loss: 0.4576 -
val\_accuracy: 0.8423 - 18s/epoch - 23ms/step
Epoch 154/200
781/781 - 18s - loss: 0.5678 - accuracy: 0.8086 - val\_loss: 0.4356 -
val\_accuracy: 0.8521 - 18s/epoch - 24ms/step
Epoch 155/200
781/781 - 17s - loss: 0.5668 - accuracy: 0.8085 - val\_loss: 0.4649 -
val\_accuracy: 0.8442 - 17s/epoch - 22ms/step
Epoch 156/200
781/781 - 19s - loss: 0.5632 - accuracy: 0.8073 - val\_loss: 0.4801 -
val\_accuracy: 0.8381 - 19s/epoch - 24ms/step
Epoch 157/200
781/781 - 18s - loss: 0.5528 - accuracy: 0.8117 - val\_loss: 0.4869 -
val\_accuracy: 0.8384 - 18s/epoch - 24ms/step
Epoch 158/200
781/781 - 18s - loss: 0.5567 - accuracy: 0.8097 - val\_loss: 0.4789 -
val\_accuracy: 0.8362 - 18s/epoch - 23ms/step
Epoch 159/200
781/781 - 18s - loss: 0.5582 - accuracy: 0.8099 - val\_loss: 0.5153 -
val\_accuracy: 0.8285 - 18s/epoch - 24ms/step
Epoch 160/200
781/781 - 18s - loss: 0.5660 - accuracy: 0.8082 - val\_loss: 0.4525 -
val\_accuracy: 0.8485 - 18s/epoch - 23ms/step
Epoch 161/200
781/781 - 18s - loss: 0.5517 - accuracy: 0.8139 - val\_loss: 0.4728 -
val\_accuracy: 0.8435 - 18s/epoch - 24ms/step
Epoch 162/200
781/781 - 18s - loss: 0.5534 - accuracy: 0.8121 - val\_loss: 0.5143 -
val\_accuracy: 0.8288 - 18s/epoch - 23ms/step
Epoch 163/200
781/781 - 18s - loss: 0.5514 - accuracy: 0.8132 - val\_loss: 0.4709 -
val\_accuracy: 0.8435 - 18s/epoch - 22ms/step
Epoch 164/200
781/781 - 19s - loss: 0.5632 - accuracy: 0.8076 - val\_loss: 0.4862 -
val\_accuracy: 0.8381 - 19s/epoch - 24ms/step
Epoch 165/200
781/781 - 18s - loss: 0.5589 - accuracy: 0.8090 - val\_loss: 0.4716 -
val\_accuracy: 0.8408 - 18s/epoch - 23ms/step
Epoch 166/200
781/781 - 18s - loss: 0.5582 - accuracy: 0.8106 - val\_loss: 0.5238 -
val\_accuracy: 0.8205 - 18s/epoch - 23ms/step
Epoch 167/200
781/781 - 18s - loss: 0.5544 - accuracy: 0.8095 - val\_loss: 0.4759 -
val\_accuracy: 0.8430 - 18s/epoch - 23ms/step
Epoch 168/200
781/781 - 18s - loss: 0.5640 - accuracy: 0.8079 - val\_loss: 0.4785 -
val\_accuracy: 0.8379 - 18s/epoch - 23ms/step
Epoch 169/200
781/781 - 18s - loss: 0.5454 - accuracy: 0.8120 - val\_loss: 0.4976 -
val\_accuracy: 0.8383 - 18s/epoch - 24ms/step
Epoch 170/200
781/781 - 18s - loss: 0.5520 - accuracy: 0.8129 - val\_loss: 0.4584 -
val\_accuracy: 0.8465 - 18s/epoch - 23ms/step
Epoch 171/200
781/781 - 18s - loss: 0.5567 - accuracy: 0.8115 - val\_loss: 0.4741 -
val\_accuracy: 0.8436 - 18s/epoch - 23ms/step
Epoch 172/200
781/781 - 19s - loss: 0.5510 - accuracy: 0.8121 - val\_loss: 0.4738 -
val\_accuracy: 0.8421 - 19s/epoch - 24ms/step
Epoch 173/200
781/781 - 18s - loss: 0.5424 - accuracy: 0.8158 - val\_loss: 0.4765 -
val\_accuracy: 0.8403 - 18s/epoch - 23ms/step
Epoch 174/200
781/781 - 19s - loss: 0.5559 - accuracy: 0.8106 - val\_loss: 0.4959 -
val\_accuracy: 0.8354 - 19s/epoch - 24ms/step
Epoch 175/200
781/781 - 18s - loss: 0.5568 - accuracy: 0.8124 - val\_loss: 0.4849 -
val\_accuracy: 0.8377 - 18s/epoch - 23ms/step
Epoch 176/200
781/781 - 18s - loss: 0.5613 - accuracy: 0.8063 - val\_loss: 0.4809 -
val\_accuracy: 0.8428 - 18s/epoch - 23ms/step
Epoch 177/200
781/781 - 19s - loss: 0.5512 - accuracy: 0.8131 - val\_loss: 0.4762 -
val\_accuracy: 0.8426 - 19s/epoch - 24ms/step
Epoch 178/200
781/781 - 18s - loss: 0.5469 - accuracy: 0.8127 - val\_loss: 0.4831 -
val\_accuracy: 0.8374 - 18s/epoch - 23ms/step
Epoch 179/200
781/781 - 19s - loss: 0.5503 - accuracy: 0.8129 - val\_loss: 0.4670 -
val\_accuracy: 0.8452 - 19s/epoch - 24ms/step
Epoch 180/200
781/781 - 19s - loss: 0.5499 - accuracy: 0.8141 - val\_loss: 0.4704 -
val\_accuracy: 0.8435 - 19s/epoch - 24ms/step
Epoch 181/200
781/781 - 18s - loss: 0.5464 - accuracy: 0.8140 - val\_loss: 0.4911 -
val\_accuracy: 0.8388 - 18s/epoch - 23ms/step
Epoch 182/200
781/781 - 19s - loss: 0.5420 - accuracy: 0.8167 - val\_loss: 0.4961 -
val\_accuracy: 0.8354 - 19s/epoch - 24ms/step
Epoch 183/200
781/781 - 18s - loss: 0.5531 - accuracy: 0.8127 - val\_loss: 0.4964 -
val\_accuracy: 0.8356 - 18s/epoch - 23ms/step
Epoch 184/200
781/781 - 18s - loss: 0.5434 - accuracy: 0.8164 - val\_loss: 0.5106 -
val\_accuracy: 0.8323 - 18s/epoch - 24ms/step
Epoch 185/200
781/781 - 19s - loss: 0.5438 - accuracy: 0.8163 - val\_loss: 0.5092 -
val\_accuracy: 0.8290 - 19s/epoch - 24ms/step
Epoch 186/200
781/781 - 17s - loss: 0.5362 - accuracy: 0.8176 - val\_loss: 0.4706 -
val\_accuracy: 0.8429 - 17s/epoch - 22ms/step
Epoch 187/200
781/781 - 18s - loss: 0.5346 - accuracy: 0.8189 - val\_loss: 0.4520 -
val\_accuracy: 0.8495 - 18s/epoch - 24ms/step
Epoch 188/200
781/781 - 18s - loss: 0.5444 - accuracy: 0.8142 - val\_loss: 0.4709 -
val\_accuracy: 0.8398 - 18s/epoch - 24ms/step
Epoch 189/200
781/781 - 18s - loss: 0.5407 - accuracy: 0.8167 - val\_loss: 0.5334 -
val\_accuracy: 0.8246 - 18s/epoch - 24ms/step
Epoch 190/200
781/781 - 19s - loss: 0.5405 - accuracy: 0.8168 - val\_loss: 0.4673 -
val\_accuracy: 0.8403 - 19s/epoch - 24ms/step
Epoch 191/200
781/781 - 18s - loss: 0.5446 - accuracy: 0.8151 - val\_loss: 0.5201 -
val\_accuracy: 0.8284 - 18s/epoch - 23ms/step
Epoch 192/200
781/781 - 19s - loss: 0.5456 - accuracy: 0.8148 - val\_loss: 0.4532 -
val\_accuracy: 0.8455 - 19s/epoch - 24ms/step
Epoch 193/200
781/781 - 18s - loss: 0.5380 - accuracy: 0.8185 - val\_loss: 0.4697 -
val\_accuracy: 0.8433 - 18s/epoch - 23ms/step
Epoch 194/200
781/781 - 19s - loss: 0.5446 - accuracy: 0.8176 - val\_loss: 0.5053 -
val\_accuracy: 0.8290 - 19s/epoch - 24ms/step
Epoch 195/200
781/781 - 19s - loss: 0.5445 - accuracy: 0.8160 - val\_loss: 0.4353 -
val\_accuracy: 0.8521 - 19s/epoch - 24ms/step
Epoch 196/200
781/781 - 18s - loss: 0.5452 - accuracy: 0.8157 - val\_loss: 0.5016 -
val\_accuracy: 0.8322 - 18s/epoch - 23ms/step
Epoch 197/200
781/781 - 18s - loss: 0.5387 - accuracy: 0.8173 - val\_loss: 0.4888 -
val\_accuracy: 0.8342 - 18s/epoch - 24ms/step
Epoch 198/200
781/781 - 18s - loss: 0.5402 - accuracy: 0.8182 - val\_loss: 0.4988 -
val\_accuracy: 0.8318 - 18s/epoch - 22ms/step
Epoch 199/200
781/781 - 18s - loss: 0.5424 - accuracy: 0.8148 - val\_loss: 0.4703 -
val\_accuracy: 0.8444 - 18s/epoch - 23ms/step
Epoch 200/200
781/781 - 18s - loss: 0.5518 - accuracy: 0.8124 - val\_loss: 0.4877 -
val\_accuracy: 0.8378 - 18s/epoch - 23ms/step
    \end{Verbatim}

    \hypertarget{evaluation}{%
\subsection{Evaluation}\label{evaluation}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{8}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{evaluation\PYZus{}t} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{it\PYZus{}train}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{[Info] Train Accuracy: }\PY{l+s+si}{\PYZob{}}\PY{n}{evaluation\PYZus{}t}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
1563/1563 [==============================] - 31s 20ms/step - loss: 0.3601 -
accuracy: 0.8741
[Info] Train Accuracy: 0.8741199970245361
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{9}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{evaluation} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{x\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test\PYZus{}cat}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{[Info] Test Accuracy: }\PY{l+s+si}{\PYZob{}}\PY{n}{evaluation}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
313/313 [==============================] - 1s 4ms/step - loss: 0.4877 -
accuracy: 0.8378
[Info] Test Accuracy: 0.8378000259399414
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{10}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{try}\PY{p}{:}
    \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{history}\PY{o}{.}\PY{n}{history}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{marker}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{o}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{history}\PY{o}{.}\PY{n}{history}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val\PYZus{}loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{marker}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{o}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Model Total Loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Epoch}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Validation}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{loc}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{upper left}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Adjust the rotation angle of x\PYZhy{}axis tick labels}
    \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{rotation}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Set rotation angle to 0 degrees}

    \PY{n}{plt}\PY{o}{.}\PY{n}{tight\PYZus{}layout}\PY{p}{(}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Adjust layout to prevent clipping of labels}
    \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\PY{k}{except} \PY{n+ne}{Exception} \PY{k}{as} \PY{n}{e}\PY{p}{:}
    \PY{n+nb}{print}\PY{p}{(}\PY{n}{e}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_17_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{11}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{try}\PY{p}{:}
    \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{history}\PY{o}{.}\PY{n}{history}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{marker}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{o}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{history}\PY{o}{.}\PY{n}{history}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val\PYZus{}accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{marker}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{o}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{model accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{epoch}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{loc}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{upper left}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{c+c1}{\PYZsh{} Adjust the rotation angle of x\PYZhy{}axis tick labels}
    \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{rotation}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Set rotation angle to 0 degrees}

    \PY{n}{plt}\PY{o}{.}\PY{n}{tight\PYZus{}layout}\PY{p}{(}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Adjust layout to prevent clipping of labels}
    \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\PY{k}{except} \PY{n+ne}{Exception} \PY{k}{as} \PY{n}{e}\PY{p}{:}
    \PY{n+nb}{print}\PY{p}{(}\PY{n}{e}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_18_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{12}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{plot\PYZus{}input\PYZus{}vs\PYZus{}predictions}\PY{p}{(}\PY{n}{model}\PY{p}{:} \PY{n}{tf}\PY{o}{.}\PY{n}{keras}\PY{o}{.}\PY{n}{models}\PY{o}{.}\PY{n}{Model}\PY{p}{,}
                              \PY{n}{x\PYZus{}test}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{ndarray}\PY{p}{,}
                              \PY{n}{y\PYZus{}test}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{ndarray}\PY{p}{,}
                              \PY{n}{class\PYZus{}names}\PY{p}{:} \PY{n+nb}{list}\PY{p}{,}
                              \PY{n}{num\PYZus{}samples}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{:}
    \PY{n}{num\PYZus{}classes} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{class\PYZus{}names}\PY{p}{)}
    \PY{n}{y\PYZus{}pred} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{x\PYZus{}test}\PY{p}{)}
    \PY{n}{y\PYZus{}pred\PYZus{}classes} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n}{y\PYZus{}pred}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}

    \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{12}\PY{p}{,} \PY{l+m+mi}{6}\PY{p}{)}\PY{p}{)}
    \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{num\PYZus{}samples}\PY{p}{)}\PY{p}{:}
        \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{num\PYZus{}samples}\PY{p}{,} \PY{n}{i} \PY{o}{+} \PY{l+m+mi}{1}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{x\PYZus{}test}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{)}
        \PY{n}{true\PYZus{}label} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{)}
        \PY{n}{predicted\PYZus{}label} \PY{o}{=} \PY{n}{y\PYZus{}pred\PYZus{}classes}\PY{p}{[}\PY{n}{i}\PY{p}{]}
        \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{True: }\PY{l+s+si}{\PYZob{}}\PY{n}{class\PYZus{}names}\PY{p}{[}\PY{n}{true\PYZus{}label}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{Predicted: }\PY{l+s+si}{\PYZob{}}\PY{n}{class\PYZus{}names}\PY{p}{[}\PY{n}{predicted\PYZus{}label}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{off}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

    \PY{n}{plt}\PY{o}{.}\PY{n}{tight\PYZus{}layout}\PY{p}{(}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}

\PY{n}{cifar10\PYZus{}class\PYZus{}names} \PY{o}{=} \PY{p}{[}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{airplane}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{automobile}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bird}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{cat}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{deer}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dog}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{frog}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{horse}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ship}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{truck}\PY{l+s+s1}{\PYZsq{}}
\PY{p}{]}

\PY{k}{try}\PY{p}{:}
    \PY{c+c1}{\PYZsh{} Plot input images vs. predictions}
    \PY{n}{plot\PYZus{}input\PYZus{}vs\PYZus{}predictions}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n}{x\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test\PYZus{}cat}\PY{p}{,} \PY{n}{class\PYZus{}names}\PY{o}{=}\PY{n}{cifar10\PYZus{}class\PYZus{}names}\PY{p}{,} \PY{n}{num\PYZus{}samples}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{)}
\PY{k}{except} \PY{n+ne}{Exception} \PY{k}{as} \PY{n}{e}\PY{p}{:}
    \PY{n+nb}{print}\PY{p}{(}\PY{n}{e}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
313/313 [==============================] - 1s 2ms/step
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_19_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{13}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{render\PYZus{}and\PYZus{}save\PYZus{}examples}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n}{example\PYZus{}data}\PY{p}{,} \PY{n}{true\PYZus{}labels}\PY{p}{,} \PY{n}{class\PYZus{}names}\PY{p}{,} \PY{n}{image\PYZus{}size}\PY{p}{)}\PY{p}{:}
    \PY{n}{examples\PYZus{}number} \PY{o}{=} \PY{n}{example\PYZus{}data}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
    \PY{n}{video\PYZus{}output\PYZus{}path} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{output\PYZus{}video.mp4}\PY{l+s+s1}{\PYZsq{}}
    \PY{n}{codec} \PY{o}{=} \PY{n}{cv2}\PY{o}{.}\PY{n}{VideoWriter\PYZus{}fourcc}\PY{p}{(}\PY{o}{*}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mp4v}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{vid\PYZus{}width\PYZus{}height} \PY{o}{=} \PY{l+m+mi}{1280}\PY{p}{,} \PY{l+m+mi}{720}
    \PY{n}{vw} \PY{o}{=} \PY{n}{cv2}\PY{o}{.}\PY{n}{VideoWriter}\PY{p}{(}\PY{n}{video\PYZus{}output\PYZus{}path}\PY{p}{,} \PY{n}{codec}\PY{p}{,} \PY{l+m+mi}{30}\PY{p}{,} \PY{n}{vid\PYZus{}width\PYZus{}height}\PY{p}{)}

    \PY{n}{font\PYZus{}face} \PY{o}{=} \PY{n}{cv2}\PY{o}{.}\PY{n}{FONT\PYZus{}HERSHEY\PYZus{}SIMPLEX}
    \PY{n}{font\PYZus{}scale} \PY{o}{=} \PY{l+m+mf}{1.3}
    \PY{n}{thickness} \PY{o}{=} \PY{l+m+mi}{2}

    \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{examples\PYZus{}number}\PY{p}{)}\PY{p}{:}
        \PY{n}{image} \PY{o}{=} \PY{n}{example\PYZus{}data}\PY{p}{[}\PY{n}{i}\PY{p}{]}
        \PY{n}{image\PYZus{}disp} \PY{o}{=} \PY{n}{cv2}\PY{o}{.}\PY{n}{resize}\PY{p}{(}\PY{n}{image} \PY{o}{*} \PY{l+m+mi}{255}\PY{p}{,} \PY{p}{(}\PY{l+m+mi}{720}\PY{p}{,} \PY{l+m+mi}{720}\PY{p}{)}\PY{p}{)}

        \PY{n}{true\PYZus{}label} \PY{o}{=} \PY{n}{true\PYZus{}labels}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}

        \PY{c+c1}{\PYZsh{} Generate predictions using the model}
        \PY{n}{predictions} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{expand\PYZus{}dims}\PY{p}{(}\PY{n}{example\PYZus{}data}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
        \PY{n}{predicted\PYZus{}label} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n}{predictions}\PY{p}{)}

        \PY{n}{predicted\PYZus{}score} \PY{o}{=} \PY{n}{predictions}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
        \PY{n}{top\PYZus{}classes} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{argsort}\PY{p}{(}\PY{n}{predicted\PYZus{}score}\PY{p}{)}\PY{p}{[}\PY{p}{:}\PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}

        \PY{n}{title} \PY{o}{=} \PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{True: }\PY{l+s+si}{\PYZob{}}\PY{n}{class\PYZus{}names}\PY{p}{[}\PY{n}{true\PYZus{}label}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{, Predicted: }\PY{l+s+si}{\PYZob{}}\PY{n}{class\PYZus{}names}\PY{p}{[}\PY{n}{predicted\PYZus{}label}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}

        \PY{n}{img} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{(}\PY{l+m+mi}{720}\PY{p}{,} \PY{l+m+mi}{1280}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}\PY{p}{,} \PY{n}{dtype}\PY{o}{=}\PY{n}{np}\PY{o}{.}\PY{n}{uint8}\PY{p}{)}
        \PY{n}{img}\PY{p}{[}\PY{p}{:}\PY{l+m+mi}{720}\PY{p}{,} \PY{p}{:}\PY{l+m+mi}{720}\PY{p}{,} \PY{p}{:}\PY{p}{]} \PY{o}{=} \PY{n}{image\PYZus{}disp}

        \PY{n}{x}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{l+m+mi}{740}\PY{p}{,} \PY{l+m+mi}{60}
        \PY{n}{is\PYZus{}correct} \PY{o}{=} \PY{n}{true\PYZus{}label} \PY{o}{==} \PY{n}{predicted\PYZus{}label}
        \PY{n}{txt\PYZus{}color} \PY{o}{=} \PY{p}{(}\PY{l+m+mi}{100}\PY{p}{,} \PY{l+m+mi}{255}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)} \PY{k}{if} \PY{n}{is\PYZus{}correct} \PY{k}{else} \PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{255}\PY{p}{)}
        \PY{n}{cv2}\PY{o}{.}\PY{n}{putText}\PY{p}{(}\PY{n}{img}\PY{p}{,} \PY{n}{text}\PY{o}{=}\PY{n}{title}\PY{p}{,} \PY{n}{org}\PY{o}{=}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{y}\PY{p}{)}\PY{p}{,} \PY{n}{fontScale}\PY{o}{=}\PY{n}{font\PYZus{}scale}\PY{p}{,} \PY{n}{fontFace}\PY{o}{=}\PY{n}{font\PYZus{}face}\PY{p}{,}
                    \PY{n}{thickness}\PY{o}{=}\PY{n}{thickness}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{n}{txt\PYZus{}color}\PY{p}{,} \PY{n}{lineType}\PY{o}{=}\PY{n}{cv2}\PY{o}{.}\PY{n}{LINE\PYZus{}AA}\PY{p}{)}

        \PY{n}{bar\PYZus{}x}\PY{p}{,} \PY{n}{bar\PYZus{}y} \PY{o}{=} \PY{l+m+mi}{740}\PY{p}{,} \PY{l+m+mi}{130}
        \PY{k}{for} \PY{n}{j}\PY{p}{,} \PY{n}{class\PYZus{}index} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{top\PYZus{}classes}\PY{p}{)}\PY{p}{:}
            \PY{k}{if} \PY{n}{j} \PY{o}{\PYZlt{}} \PY{l+m+mi}{10}\PY{p}{:}
                \PY{n}{p} \PY{o}{=} \PY{n}{predicted\PYZus{}score}\PY{p}{[}\PY{n}{class\PYZus{}index}\PY{p}{]} \PY{o}{*} \PY{l+m+mi}{100}
                \PY{n}{rect\PYZus{}width} \PY{o}{=} \PY{n+nb}{int}\PY{p}{(}\PY{n}{p} \PY{o}{*} \PY{l+m+mf}{3.3}\PY{p}{)}
                \PY{n}{rect\PYZus{}start} \PY{o}{=} \PY{l+m+mi}{180}
                \PY{n}{color} \PY{o}{=} \PY{p}{(}\PY{l+m+mi}{255}\PY{p}{,} \PY{l+m+mi}{218}\PY{p}{,} \PY{l+m+mi}{158}\PY{p}{)} \PY{k}{if} \PY{n}{class\PYZus{}index} \PY{o}{==} \PY{n}{true\PYZus{}label} \PY{k}{else} \PY{p}{(}\PY{l+m+mi}{100}\PY{p}{,} \PY{l+m+mi}{100}\PY{p}{,} \PY{l+m+mi}{100}\PY{p}{)}
                \PY{n}{cv2}\PY{o}{.}\PY{n}{rectangle}\PY{p}{(}\PY{n}{img}\PY{p}{,} \PY{p}{(}\PY{n}{bar\PYZus{}x} \PY{o}{+} \PY{n}{rect\PYZus{}start}\PY{p}{,} \PY{n}{bar\PYZus{}y} \PY{o}{\PYZhy{}} \PY{l+m+mi}{5}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{n}{bar\PYZus{}x} \PY{o}{+} \PY{n}{rect\PYZus{}start} \PY{o}{+} \PY{n}{rect\PYZus{}width}\PY{p}{,} \PY{n}{bar\PYZus{}y} \PY{o}{\PYZhy{}} \PY{l+m+mi}{20}\PY{p}{)}\PY{p}{,}
                              \PY{n}{color}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}
                \PY{n}{text} \PY{o}{=} \PY{l+s+sa}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}}\PY{n}{class\PYZus{}names}\PY{p}{[}\PY{n}{class\PYZus{}index}\PY{p}{]}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{: }\PY{l+s+si}{\PYZob{}}\PY{n+nb}{int}\PY{p}{(}\PY{n}{p}\PY{p}{)}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{\PYZsq{}}
                \PY{n}{cv2}\PY{o}{.}\PY{n}{putText}\PY{p}{(}\PY{n}{img}\PY{p}{,} \PY{n}{text}\PY{o}{=}\PY{n}{text}\PY{p}{,} \PY{n}{org}\PY{o}{=}\PY{p}{(}\PY{n}{bar\PYZus{}x}\PY{p}{,} \PY{n}{bar\PYZus{}y}\PY{p}{)}\PY{p}{,} \PY{n}{fontScale}\PY{o}{=}\PY{n}{font\PYZus{}scale}\PY{p}{,} \PY{n}{fontFace}\PY{o}{=}\PY{n}{font\PYZus{}face}\PY{p}{,}
                            \PY{n}{thickness}\PY{o}{=}\PY{n}{thickness}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{n}{color}\PY{p}{,} \PY{n}{lineType}\PY{o}{=}\PY{n}{cv2}\PY{o}{.}\PY{n}{LINE\PYZus{}AA}\PY{p}{)}
                \PY{n}{bar\PYZus{}y} \PY{o}{+}\PY{o}{=} \PY{l+m+mi}{60}
        \PY{n}{img} \PY{o}{=} \PY{n}{cv2}\PY{o}{.}\PY{n}{cvtColor}\PY{p}{(}\PY{n}{img}\PY{p}{,} \PY{n}{cv2}\PY{o}{.}\PY{n}{COLOR\PYZus{}BGR2RGB}\PY{p}{)}
        \PY{n}{vw}\PY{o}{.}\PY{n}{write}\PY{p}{(}\PY{n}{img}\PY{p}{)} \PY{k}{if} \PY{n}{true\PYZus{}label} \PY{o}{==} \PY{n}{predicted\PYZus{}label} \PY{k}{else} \PY{k+kc}{None}

    \PY{n}{vw}\PY{o}{.}\PY{n}{release}\PY{p}{(}\PY{p}{)}

\PY{k}{try}\PY{p}{:}
    \PY{c+c1}{\PYZsh{} Select random 60 indices}
    \PY{n}{random\PYZus{}indices} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{choice}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{x\PYZus{}test}\PY{p}{)}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m+mi}{60}\PY{p}{,} \PY{n}{replace}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
    \PY{n}{selected\PYZus{}x\PYZus{}test} \PY{o}{=} \PY{n}{x\PYZus{}test}\PY{p}{[}\PY{n}{random\PYZus{}indices}\PY{p}{]}
    \PY{n}{selected\PYZus{}y\PYZus{}test} \PY{o}{=} \PY{n}{y\PYZus{}test}\PY{p}{[}\PY{n}{random\PYZus{}indices}\PY{p}{]}

    \PY{c+c1}{\PYZsh{} Use the function with your data and model}
    \PY{n}{render\PYZus{}and\PYZus{}save\PYZus{}examples}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n}{selected\PYZus{}x\PYZus{}test}\PY{p}{,} \PY{n}{selected\PYZus{}y\PYZus{}test}\PY{p}{,} \PY{n}{cifar10\PYZus{}class\PYZus{}names}\PY{p}{,}  \PY{l+m+mi}{32}\PY{p}{)}
\PY{k}{except} \PY{n+ne}{Exception} \PY{k}{as} \PY{n}{e}\PY{p}{:}
    \PY{n+nb}{print}\PY{p}{(}\PY{n}{e}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{14}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} @title}
\PY{k+kn}{from} \PY{n+nn}{IPython}\PY{n+nn}{.}\PY{n+nn}{display} \PY{k+kn}{import} \PY{n}{HTML}
\PY{k+kn}{from} \PY{n+nn}{base64} \PY{k+kn}{import} \PY{n}{b64encode}

\PY{n}{video\PYZus{}path} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{output\PYZus{}video.mp4}\PY{l+s+s1}{\PYZsq{}}

\PY{k}{def} \PY{n+nf}{show\PYZus{}video}\PY{p}{(}\PY{n}{video\PYZus{}path}\PY{p}{,} \PY{n}{video\PYZus{}width} \PY{o}{=} \PY{l+m+mi}{600}\PY{p}{)}\PY{p}{:}
    \PY{n}{video\PYZus{}file} \PY{o}{=} \PY{n+nb}{open}\PY{p}{(}\PY{n}{video\PYZus{}path}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{r+b}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{read}\PY{p}{(}\PY{p}{)}
    \PY{n}{video\PYZus{}url} \PY{o}{=} \PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{data:video/mp4;base64,}\PY{l+s+si}{\PYZob{}}\PY{n}{b64encode}\PY{p}{(}\PY{n}{video\PYZus{}file}\PY{p}{)}\PY{o}{.}\PY{n}{decode}\PY{p}{(}\PY{p}{)}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}
    \PY{k}{return} \PY{n}{HTML}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}\PYZdq{}\PYZdq{}}\PY{l+s+s2}{\PYZlt{}video width=}\PY{l+s+si}{\PYZob{}}\PY{n}{video\PYZus{}width}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{ controls\PYZgt{}\PYZlt{}source src=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+si}{\PYZob{}}\PY{n}{video\PYZus{}url}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZgt{}\PYZlt{}/video\PYZgt{}}\PY{l+s+s2}{\PYZdq{}\PYZdq{}\PYZdq{}}\PY{p}{)}

\PY{n}{show\PYZus{}video}\PY{p}{(}\PY{n}{video\PYZus{}path}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{14}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
<IPython.core.display.HTML object>
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{15}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{try}\PY{p}{:}
    \PY{c+c1}{\PYZsh{} Open the video file}
    \PY{n}{video\PYZus{}path} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./output\PYZus{}video.mp4}\PY{l+s+s1}{\PYZsq{}}
    \PY{n}{cap} \PY{o}{=} \PY{n}{cv2}\PY{o}{.}\PY{n}{VideoCapture}\PY{p}{(}\PY{n}{video\PYZus{}path}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Get the total number of frames in the video}
    \PY{n}{total\PYZus{}frames} \PY{o}{=} \PY{n+nb}{int}\PY{p}{(}\PY{n}{cap}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{n}{cv2}\PY{o}{.}\PY{n}{CAP\PYZus{}PROP\PYZus{}FRAME\PYZus{}COUNT}\PY{p}{)}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Select a random frame index}
    \PY{n}{random\PYZus{}frame\PYZus{}index} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{randint}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{total\PYZus{}frames}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Set the frame index}
    \PY{n}{cap}\PY{o}{.}\PY{n}{set}\PY{p}{(}\PY{n}{cv2}\PY{o}{.}\PY{n}{CAP\PYZus{}PROP\PYZus{}POS\PYZus{}FRAMES}\PY{p}{,} \PY{n}{random\PYZus{}frame\PYZus{}index}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Read the selected frame}
    \PY{n}{ret}\PY{p}{,} \PY{n}{frame} \PY{o}{=} \PY{n}{cap}\PY{o}{.}\PY{n}{read}\PY{p}{(}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Check if the frame was read successfully}
    \PY{k}{if} \PY{o+ow}{not} \PY{n}{ret}\PY{p}{:}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Error reading frame from the video.}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{cap}\PY{o}{.}\PY{n}{release}\PY{p}{(}\PY{p}{)}
    \PY{k}{else}\PY{p}{:}
        \PY{c+c1}{\PYZsh{} Convert BGR to RGB for matplotlib display}
        \PY{n}{frame\PYZus{}rgb} \PY{o}{=} \PY{n}{frame}

        \PY{c+c1}{\PYZsh{} Plot the frame}
        \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{frame\PYZus{}rgb}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Random Frame (}\PY{l+s+si}{\PYZob{}}\PY{n}{random\PYZus{}frame\PYZus{}index}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{/}\PY{l+s+si}{\PYZob{}}\PY{n}{total\PYZus{}frames}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{)}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{off}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}

    \PY{c+c1}{\PYZsh{} Release the video capture object}
    \PY{n}{cap}\PY{o}{.}\PY{n}{release}\PY{p}{(}\PY{p}{)}
\PY{k}{except} \PY{n+ne}{Exception} \PY{k}{as} \PY{n}{e}\PY{p}{:}
    \PY{n+nb}{print}\PY{p}{(}\PY{n}{e}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_22_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{16}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{try}\PY{p}{:}
    \PY{n}{model}\PY{o}{.}\PY{n}{save}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{cifar10\PYZhy{}model.h5}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{k}{except} \PY{n+ne}{Exception} \PY{k}{as} \PY{n}{e}\PY{p}{:}
    \PY{n+nb}{print}\PY{p}{(}\PY{n}{e}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{conclusion}{%
\subsection{Conclusion:}\label{conclusion}}

In culmination, the designed CNN classifier has yielded promising
results. Achieving an accuracy rate of 88\% demonstrates the potency of
CNNs in discerning patterns within images. However, this is just the
beginning of the exploration. Leveraging pre-trained models and
employing more complex architectures offer avenues for refinement. The
augmentation of data and the optimization of parameters like batch size
and learning rate can further enhance performance. With ample
computational resources and the spirit of experimentation, the potential
to unravel greater accuracy and capabilities within the classifier
remains a tantalizing prospect.


    % Add a bibliography block to the postdoc
    
    
    
\end{document}
